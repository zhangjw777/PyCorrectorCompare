# 本项目用于训练政府公文文本错误的**检测**模型，以 MacBERT 为基础设计多任务预测结构。

模型由三部分组成：

* **编码层（Encoder）**：使用 MacBERT-Base / MacBERT-Large 作为预训练编码器，输入为字级/子词级的公文文本序列，输出共享表示 $H_{shared}$。
* **多任务预测层（Multi-Task Heads）**：

  * **主任务头：序列标注检错头（GEC-style Error Detection Tagging Head）**
    预测编辑标签（KEEP / DELETE / APPEND / REPLACE），用于标记每个位置是否存在“多字、少字、错字”等错误类型，**只用于错误位置与类型的检测，不生成具体纠正内容**。
  * **辅助任务头 1：全句错误检测（Sentence-level Detection）**
    基于错误感知多实例结构判断句子是否存在错误。
  * **辅助任务头 2：核心句法成分识别（Core Component Recognition, SVO 任务）**
    预测每个字是否属于主语（Subject）、谓语（Predicate）或宾语（Object），让模型显式感知句子的“骨架”，从而更好识别“主语缺失”“谓语残缺”等结构性病句。
  * **句法–语义融合交互层（Syntax–Semantic Interaction Layer）**
    插入在编码层输出与GED主任务头之间，将 SVO 任务学到的句法表示显式注入到主任务的 token 表示中。
* **损失函数层**：
  主任务使用加权 Focal Loss 解决样本极度不平衡问题，三个任务的损失通过**基于不确定性的动态加权策略**进行自适应融合，替代简单的固定权重 Cross Entropy 组合。

---

### 核心改进一：序列标注体系的领域化定制（检错导向）

原生 GECToR 包含大量针对英文的标签（如动词时态变换、单复数变换），不适合中文公文场景。**本研究只关注“是否有错、错误类型是什么”**，不直接输出具体纠正内容，因此对标签体系进行领域化、检错导向的简化设计：

* **KEEP**：保持不变（正确字，占比 90%+）。
* **DELETE**：删除该字（用于“成分赘余”类错误，如重复字、多余成分）。
* **APPEND**：在该字后“存在成分缺失”（用于“成分缺失”类错误，如缺少介词、结构助词等），仅标记缺失位置，不预测具体插入的字符。
* **REPLACE**：该字用词不当 / 搭配错误（“错词、误用”），标记该位置需要替换，但不预测替换后的具体字符。

> 说明：
> 在**数据构造与增强阶段**，仍可以利用公文高频虚词和音形近混淆集合成 APPEND/REPLACE 类型错误，以提高模型对真实错误的覆盖度；但在**模型输出与评估阶段**，仅使用上述 4 类标签进行错误检测，不评估具体纠正结果，从而保持“只做检错”的任务边界。

---

### 核心改进二：引入 Focal Loss 优化检错召回率

在检错任务中，正样本（错误字）与负样本（正确字）的比例极其悬殊（往往达到 1:50 甚至更低）。若直接使用标准交叉熵损失（Cross Entropy, CE），模型会倾向于大量预测 KEEP 以最小化平均 Loss，导致错误检测的召回率严重偏低。

为此，在**主任务GED序列标注**中引入 Focal Loss，对错误样本进行“聚焦”：

$$
FL(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t)
$$

* $p_t$：模型对**真实标签**的预测概率；
* $\gamma$（聚焦参数）：建议设为 2.0。
  当某个字实际上是错误字但模型仍强烈倾向于预测 KEEP 时（$p_t$ 较小），$(1 - p_t)^\gamma$ 会放大该样本的损失，强迫模型关注这些“难样本”。
* $\alpha_t$（平衡参数）：针对 KEEP 类设为 0.25，针对错误类（DELETE / APPEND / REPLACE）设为 0.75，显式提高错误类的权重。

**理论意义**：通过调整 $\gamma$ 和 $\alpha$，可以灵活控制模型对错误样本的“敏感度”。在公文检错场景下，适当调大错误类权重能显著提升召回率，虽然会牺牲少量精确率，但更符合“宁可多报、不要漏报”的业务需求。

---

### 核心改进三：多任务学习（MTL）结构与句法监督信号

为应对公文中最棘手的“成分残缺”问题，本研究在 MacBERT 顶层引入**句法结构监督信号**，构建多任务学习框架：

#### 1. 辅助任务定义：核心成分（SVO）序列标注

传统的词性标注（POS）只提供浅层语法信息（如“会议”为名词），无法表征其在句中充当“主语”还是“宾语”。因此将辅助任务升级为**核心成分序列标注**：

* **目标**：预测输入序列中每个 token 的句法角色；
* **标签体系**：采用 BIO 标注模式的简化句法标签：

  * B-SUB, I-SUB：主语成分（Subject）
  * B-PRED, I-PRED：谓语 / 核心动词成分（Predicate）
  * B-OBJ, I-OBJ：宾语成分（Object）
  * O：其他成分（定状补、虚词等）

> 注：公文检错主要关心主谓宾“骨架”的完整性，故忽略细粒度定状补标签，以降低任务难度并突出结构性错误。

#### 2. 网络结构

* 编码层输出共享表示 $H_{shared}$，供三个任务共同使用；
* SVO 任务在 $H_{shared}$ 上接一个轻量的 token-level 分类头，输出 SVO 标签；
* 序列标注检错主任务在经过**句法–语义融合交互层**处理后的表示 $H_{ged\_input}$ 上进行 edit 标签预测；
* 句级错误检测任务基于“错误感知多实例 Head”构造句级表示并做二分类。

在最直接的多任务设置中，总损失可以写为：

$$
L_{total}^{\text{base}} = L_{GED} + \lambda_1 L_{SVO} + \lambda_2 L_{Sent}
$$

其中：

* $L_{GED}$：主任务检错损失（本研究中采用 Focal Loss）；
* $L_{SVO}$：核心成分识别损失（交叉熵）；
* $L_{Sent}$：句级错误检测损失（如 BCEWithLogitsLoss）；
* $\lambda_1, \lambda_2$：多任务权重超参数。

固定权重的形式虽然简单，但缺乏理论依据且调参成本高，难以自适应地平衡三个任务的学习进度。**在此基础上，本研究进一步在“核心改进五”中引入不确定性加权替代固定的 $\lambda$。**

---

### 核心改进四：句法–语义融合交互层（Syntax–Semantic Interaction Layer）

为了让 SVO 辅助任务中学到的句法信息**显式地指导** 主任务，而非仅仅作为并行的辅助监督，本研究在 MacBERT 编码器输出层与 ged 预测头之间引入**句法–语义融合门控单元**。

**结构设计：**

* 由共享表示 $H_{shared}$ 经过一层变换生成 SVO 中间表示 $H_{SVO}$；
* 将 $H_{shared}$ 与 $H_{SVO}$ 在最后一维拼接，经门控网络生成门控向量 $G$；
* 将句法信息变换后注入主任务输入表示，得到 $H_{ged\_input}$。

公式如下：

$$
G = \sigma\big(W_g \cdot [H_{shared}; H_{SVO}] + b_g\big)
$$

$$
T = W_t \cdot H_{SVO} + b_t
$$

$$
H_{ged\_input} = H_{shared} + G \odot T
$$

其中：

* $[H_{shared}; H_{SVO}]$：在特征维度上的拼接；
* $G$：门控系数（0–1 之间），按元素控制句法信息注入程度；
* $T$：对 $H_{SVO}$ 做线性变换后的句法特征；
* $\odot$：逐元素乘法。

**理论意义**：该设计实现了“基于显式句法先验指导的序列标注”（Syntax-guided Sequence Labeling）。句法信息不再仅仅作为独立的监督信号，而是直接参与构建主任务的 token 表示，增强模型对句子结构完整性的感知能力。

---

### 核心改进五：基于不确定性的动态损失加权（Uncertainty-Weighted Loss）

如前所述，固定 $\lambda_1, \lambda_2$ 的多任务加权方式缺乏自适应性。本研究引入**同方差不确定性加权**（Homoscedastic Uncertainty Weighting），由模型自动学习各任务的权重。

**一般形式：**

$$
L_{total} = \frac{1}{2\sigma_1^2}L_{GED} + \frac{1}{2\sigma_2^2}L_{SVO} + \frac{1}{2\sigma_3^2}L_{Sent} + \log(\sigma_1\sigma_2\sigma_3)
$$

其中 $\sigma_i$ 代表任务 $i$ 的不确定性，均为可学习参数。为提升数值稳定性，实际实现中使用对数方差形式 $s_i = \log(\sigma_i^2)$：

$$
L_{total} = \frac{1}{2}e^{-s_1}L_{GED}
+ \frac{1}{2}e^{-s_2}L_{SVO}
+ \frac{1}{2}e^{-s_3}L_{Sent}
+ \frac{1}{2}(s_1 + s_2 + s_3)
$$

**理论意义：**

* 不确定性大的任务会被自动赋予更小权重（$e^{-s_i}$ 更小），避免难任务主导训练；
* 模型能够自适应地平衡主任务、SVO 与句级检测三种任务的学习过程；
* 训练过程中可绘制 $s_i$ 随 epoch 变化的曲线，分析各任务学习难度与收敛速度。

---

### 核心改进六：错误感知多实例句级分类头（Error-Aware Multi-Instance Head）

原有的句级错误检测头仅使用 `[CLS]` 表示进行二分类，难以显式利用 token 级错误信息。本研究将其升级为**错误感知多实例学习（Multi-Instance Learning, MIL）结构**。

**核心思想**：将句子视为由 token 构成的“实例集合”（bag of instances），句子是否有错取决于集合中是否存在“错误 token 实例”。

**设计步骤：**

1. **错误置信度计算**
   从主任务 Head 的输出中，获取每个 token 被预测为 KEEP 的概率 $P(label_i = \text{KEEP})$，定义错误置信度：

   $$
   e_i = 1 - P(label_i = \text{KEEP})
   $$

2. **错误驱动注意力权重**
   使用错误置信度作为注意力分数，对句内 token 做 softmax（对 padding 位置进行 mask）：

   $$
   \alpha_i = \text{softmax}(e_i)
   $$

3. **错误感知池化构造句级表示**
   以融合后的 token 表示 $H_i$（即 $H_{ged\_input, i}$）为基础，做加权求和：

   $$
   V_{sent} = \sum_i \alpha_i \cdot H_i
   $$

4. **句级预测**
   将句级向量 $V_{sent}$ 输入 MLP 得到最终句级预测：

   $$
   y_{sent} = \text{MLP}(V_{sent})
   $$

句级标签可以通过两种方式获得：

* 若有人工标注句级“有错 / 无错”，直接使用；
* 若仅有 token 级 edit 标签，则自动构造：若该句存在任何非 KEEP 标签，则句级标签为“有错”，否则为“无错”。

**理论意义：**

* 显式建模 token-level error evidence 与 sentence-level correctness 的对齐关系；
* 解决传统 `[CLS]` 池化难以关注关键错误 token 的问题；
* 通过注意力权重可视化，可以展示模型“认为最可疑”的位置，提升句级判断的可解释性。

---

### 基于规则的错误生成（Rule-based Error Generation）

公文领域标注数据极其稀缺，因此必须采用数据增强（Data Augmentation）技术，利用公文特有的语言学特征**反向生成错误样本**，为检错模型提供足够多的训练实例。

1. **混淆集替换（Confusion Set Substitution）**
   建立公文常用词的音近 / 形近混淆集（如“权力” vs “权利”，“法治” vs “法制”等），在正确语料中随机替换相应词语，生成“用词不当、概念混淆”类错误，对应 REPLACE 标签。

2. **介词 / 助词掩码（Preposition & Particle Masking）**
   针对“成分缺失”，编写规则随机删除句首的介词（如“通过”“根据”）或句中的结构助词（如“的”“地”），模拟真实中的成分残缺错误，对应 APPEND / DELETE 类标签。 

---

### 深度生成模型（CNEG 与 EdaCSC）（暂不实现，保留为后续扩展方向）

为进一步提升错误样本的多样性与自然度，可以考虑引入更高级的深度生成方法（作为后续工作）：

* **CNEG（Conditional Non-Autoregressive Error Generation）**：
  训练一个条件非自回归生成模型，以正确句子为输入，生成带有错误的句子。该方法能够产生更自然、符合人类犯错规律的错误模式。

* **EdaCSC 策略**：

  * **Split Sentences**：将长篇公文切分为短句进行训练，减弱模型对过长上下文的依赖，增强局部检错能力。
  * **Reduce Typos**：控制训练集中“多错句”的比例，防止模型学会“一句只改一处”的简单策略，更贴近真实场景中一条公文可能存在多处错误的情况。

***

